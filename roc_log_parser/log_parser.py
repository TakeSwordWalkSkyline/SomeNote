# -*- coding: utf-8 -*-
#!/usr/local/bin/python
import json
import numpy
import pprint
import re
import sys
import xlsxwriter

log_r = r'\[log\]'
apnd_r = r'\[append\]\s+(\d+)'
actt_r = r'\[activate\]\s+(\d+)\s+(\d+)\s+(\d+)\s+(\d+)'
flnm_r = r'\[filename\]'
rst_r = r'\[reset\]\s+(\d+)'
strt_r = r'\[start\]\s+(\d+)'
chk_r = r'\[check\]\s+(\d+)\s+(\d+)\s+(\d+\.\d+)'

JN = 'JN'
JW = 'JW'

if len(sys.argv) != 4:
    print("""Submodule for parsing logs generated by test_term_wakeup

Usage: """ + sys.argv[0] + " <positive_log> " + " <negative_log>" + " <caselist>" )
    exit(1)

log_jn = sys.argv[1]
log_jw = sys.argv[2]
caselist = sys.argv[3]

def get_case_number(caselist):
    """Get line number from file caselist."""
    num = 0
    with open(caselist, 'r') as casefile:
        for line in casefile:
            if line.strip().startswith('#') is False:
                num = num + 1
    return num


def collect_word(caselist):
    """Read line from case configuration file and collect all the keywords, each
line MUST be a valid json with key 'word', 'property' and 'args', where 'args'
is a JSON containing key 'term' and 'filelist'. This function terminates on any
parse error. Return a map between keyword id and keyword string, and map between
keyword id and keyword case number.

    """
    keywords = {}
    total = {}
    with open(caselist, 'r') as cases:
        for line in cases:
            case = json.loads(line)
            if case['property'] == 'jn':
                args = case['args']
                term = args['term']
                keywords[str(term)] = case['word']
                total[str(term)] = get_case_number(args['filelist'])
    return keywords, total

# map between keyword id and keyword string
# map between keyword id and keyword case number
keywords, total = collect_word(caselist)

def tokentype(line):
    if re.match(log_r, line):
        return 'LOG'
    elif re.match(apnd_r, line):
        return 'APND'
    elif re.match(actt_r, line):
        return 'ACT'
    elif re.match(flnm_r, line):
        return 'FLN'
    elif re.match(rst_r, line):
        return 'RST'
    elif re.match(strt_r, line):
        return 'ST'
    elif re.match(chk_r, line):
        return 'CHK'
    else:
        return 'UNK'


def merge_candidate(dict1, dict2):
    """merge dict2 into dict1, dict1 is dict of vectors, dict2 is dict of dict"""
    for key, value in dict2.iteritems():
        for k2, v2 in value.iteritems():
            if key not in dict1:
                dict1[key] = [v2]
            else:
                dict1[key].append(v2)


def add_result(summary, case):
    """put a case into summary list"""
    t = case['type']
    if t not in summary:
        summary[t] = []
    case.pop('type')
    summary[t].append(case)


def count_if_larger(arr, value):
    count = 0
    for v in arr:
        if v > value:
            count += 1
    return count


def count_if_smaller(arr, value):
    count = 0
    for v in arr:
        if v <= value:
            count += 1
    return count


def parse_log(log, case):
    """parse a log that matches the format as regexp defined above"""
    cases = {}
    case = {}
    new = False
    candidate = None
    with open(log, 'r') as log_f:
        for line in log_f:
            line = line.strip()
            type = tokentype(line)
            if type == 'LOG':
                if len(case) > 0:
                    add_result(cases, case)
                    case = {}
                    candidate = None
            elif type == 'APND':
                case['type'] = JN
            elif type == 'ACT':
                case['type'] = JW
            elif type == 'FLN':
                if new:
                    if candidate is not None:
                        merge_candidate(case, candidate)
                        candidate = None
                new = not new
            elif type == 'RST':
                if candidate is not None:
                    merge_candidate(case, candidate)
                    candidate = None
            elif type == 'ST':
                if candidate is not None:
                    merge_candidate(case, candidate)
                    candidate = None
            elif type == 'CHK':
                m = re.match(chk_r, line)
                id = int(m.group(1))
                start = int(m.group(2))
                cm = float(m.group(3))
                if case['type'] == JN:
                    if candidate is None:
                        candidate = {m.group(1): {start: cm}}
                    elif m.group(1) not in candidate:
                        candidate[m.group(1)] = {start: cm}
                    else:
                        for k, v in candidate[m.group(1)].iteritems():
                            if v < cm: 
                                candidate[m.group(1)][k] = cm
                elif case['type'] == JW:
                    if candidate is None:
                         candidate = {m.group(1): {start: cm}}
                    elif m.group(1) not in candidate:
                        candidate[m.group(1)] = {start: cm}
                    elif start not in candidate[m.group(1)]:
                        candidate[m.group(1)][start] = cm
                    elif candidate[m.group(1)][start] < cm:
                        candidate[m.group(1)][start] = cm
                    else:
                        candidate[m.group(1)][start] = candidate[m.group(1)][start]
                else:
                    print("Invalid type of case: " + case['type'])
            else:
                print("Invalid operation: " + line)

    if len(case) > 0:
        add_result(cases, case)
        case = []
        candidate = None

    for key, value in cases.iteritems():
        for item in value:
            for k, v in item.iteritems():
                if isinstance(v, list):
                    item[k].sort()
    return cases

result_empty = {}
print ('parse jn log')
result_jn = parse_log(log_jn, result_empty)
# a vector of dicts, length of number of keywords
jn_results = result_jn[JN]

print ('parse jw log')
result = parse_log(log_jw, result_jn)
# a vector of dicts, number of keywords items, length is 1
jw_results = result[JW]

# seq1 = numpy.linspace(0.001, 0.009, 9)
seq2 = numpy.linspace(0.01, 1.0, 100)
seq = seq2

roc = {}
for threshold in seq:
    for jn_dict in jn_results:
        for k, v in jn_dict.iteritems():
            # both jn_rst and jw_rst is a vector
            jn_rst = v
            if k in jw_results[0]:
                jw_rst = jw_results[0][k]
            else:
                jw_rst = []
            jn_number = count_if_larger(jn_rst, threshold)
            jw_number = count_if_larger(jw_rst, threshold)
            one = (threshold, jw_number / 51.37,
                   1 - float(jn_number) / total[k])
            if k in roc:
                roc[k].append(one)
            else:
                roc[k] = [one]

workbook = xlsxwriter.Workbook('roc.xlsx')
cell_format1 = workbook.add_format()
cell_format1.set_border()
cell_format3 = workbook.add_format()
cell_format3.set_border()
cell_format3.set_num_format('0.00%')
line_format = [cell_format1, cell_format1, cell_format3]

for k, v in roc.iteritems():
    name = keywords[k]
    worksheet = workbook.add_worksheet(name)
    row = 0
    worksheet.write(row, 0, u'阈值', cell_format1)
    worksheet.write(row, 1, u'FA', cell_format1)
    worksheet.write(row, 2, u'FR', cell_format1)
    row += 1
    for tup in v:
        col = 0
        for ele in tup:
            worksheet.write(row, col, ele, line_format[col])
            col += 1
        row += 1

workbook.close()
